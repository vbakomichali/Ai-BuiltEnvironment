{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbakomichali/Ai-BuiltEnvironment/blob/main/IAAC2024_YOLO_Finetune_finetune_VB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "LpRCcCtWJ_yL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyR7MrQRVtbi"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics==8.0.196"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "import cv2"
      ],
      "metadata": {
        "id": "KfUm2P7qZG3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import pickle\n",
        "HOME = \"/content\""
      ],
      "metadata": {
        "id": "ta6ubJWVafxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach A: Local File"
      ],
      "metadata": {
        "id": "_RwuveOjIxcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92YG2UgzYaXq",
        "outputId": "1251bada-9938-4086-9e2d-1d23f7071313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dataset from google drive to colab\n",
        "source_dir = '/content/drive/MyDrive/iaac2024/ViennaSatImages/Datasets/RoofAndContext/'\n",
        "dest_dir = '/content/datasets/'\n",
        "\n",
        "shutil.copytree(source_dir, dest_dir, dirs_exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VnM689x7hxKV",
        "outputId": "729e6b35-8346-47ad-a454-79d7a1949416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/datasets/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approach B: via API from roboflow"
      ],
      "metadata": {
        "id": "FiZyu4svI5om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# paste snippet from roboflow\n"
      ],
      "metadata": {
        "id": "EjhW-MaZI9ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training / fine-tuning the model"
      ],
      "metadata": {
        "id": "lf_nJYF4rBUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%cd {HOME}\n",
        "HOME=\"ll\""
      ],
      "metadata": {
        "id": "0j-c0xx1itRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights if pretrained model and train!\n",
        "# paramter documentation: https://docs.ultralytics.com/modes/train/#clearml\n",
        "\n",
        "model_ori = YOLO(\"yolov8s.pt\")\n",
        "training_res = model_ori.train(data=\"/content/RoofAndContext/data.yaml\", epochs=12, imgsz=640)"
      ],
      "metadata": {
        "id": "Oj9CnvO6lBUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the fine-tuned model"
      ],
      "metadata": {
        "id": "yhcCzLGnrHP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_model = f'/content/runs/detect/train3/weights/best.pt'\n",
        "model = YOLO(path_to_model)"
      ],
      "metadata": {
        "id": "dr3z8eYnalIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download model weights\n",
        "files.download(path_to_model)"
      ],
      "metadata": {
        "id": "xqIivaftmNIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the fine tuned model"
      ],
      "metadata": {
        "id": "LOPlLW6tmQQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run model on image\n",
        "results = model.predict(source='/content/RoofAndContext/valid/images/slice_115_jpg.rf.6c7c12609c011f05d39c64a2b5d5b301.jpg', conf=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diYEI8yqk1It",
        "outputId": "a6522fa9-5e17-4bc5-9a74-ddafd1ab5d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/RoofAndContext/valid/images/slice_115_jpg.rf.6c7c12609c011f05d39c64a2b5d5b301.jpg: 640x640 9 flatroofs, 27 trees, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets have look how the \"results\" look like"
      ],
      "metadata": {
        "id": "lUYiVBAN8W7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the documentation\n",
        "help(results[0])"
      ],
      "metadata": {
        "id": "qaL144nTw4ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check available methods\n",
        "dir(results[0])"
      ],
      "metadata": {
        "id": "ebjnUdUrxDly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get documentation of plotting parameter\n",
        "print(help(results[0].plot))"
      ],
      "metadata": {
        "id": "KGOGA8qK66SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the inbuilt \"plot\" method to visualise the annotated image\n",
        "results[0].plot(conf=False, line_width=2, labels=True)"
      ],
      "metadata": {
        "id": "0ktO5iruvJ-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to extract the number of detections for each class"
      ],
      "metadata": {
        "id": "90ZJz4Ui5dU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getDetectionCountsAndLocation(res):\n",
        "  # create a dictionary for each class\n",
        "  classNameMapper = res.names # id -> name mapper is automatically created\n",
        "\n",
        "  # create a dictionary with an entry for each class name and a initial coutner set to 0\n",
        "  classCount = { v:0 for k, v in classNameMapper.items()}\n",
        "  for bbox_id in  res.boxes.cls.tolist():\n",
        "    className = classNameMapper[bbox_id]\n",
        "    classCount[className] += 1\n",
        "  # store center point of each prediction\n",
        "  objLocations = { v:[] for k, v in classNameMapper.items()}\n",
        "  for box in  res.boxes:\n",
        "     bbox_id = box.cls.tolist()[0]\n",
        "     className = classNameMapper[bbox_id]\n",
        "     corners = box.xyxy.tolist()[0]\n",
        "     centerPt =   [corners[0] + corners[2] / 2 , corners[1] + corners[3] / 2]\n",
        "     objLocations[className].append(centerPt)\n",
        "\n",
        "  #print(classCount)\n",
        "  return classCount, objLocations"
      ],
      "metadata": {
        "id": "Xy7-DzZFvil8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting object counts an annoted image"
      ],
      "metadata": {
        "id": "LIkGr0iJ7x_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detectionResults = []\n",
        "for res in results:\n",
        "  resDict = {}\n",
        "  resDict[\"image\"] = res.plot(conf=False, line_width=2, labels=True, pil=True)\n",
        "\n",
        "  # get counts and detection\n",
        "  detectionCount, detectionLocation = getDetectionCountsAndLocation(res)\n",
        "  print (detectionLocation)\n",
        "  resDict[\"detectionCount\"] = detectionCount\n",
        "  resDict[\"detectionLocation\"] = detectionLocation\n",
        "\n",
        "  detectionResults.append(resDict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDnnrk62t3vZ",
        "outputId": "1567f553-5a28-4e88-da38-2bc02a8214d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'flatroof': [[678.0396118164062, 490.8361511230469], [281.3410949707031, 186.37432098388672], [388.1791534423828, 42.92464828491211], [642.6951751708984, 834.5809936523438], [157.1570816040039, 26.415451049804688], [283.78245544433594, 288.13836669921875], [277.1182098388672, 46.087669372558594], [817.7100830078125, 549.7976226806641], [464.69276428222656, 849.0652465820312]], 'tree': [[299.2652893066406, 422.5239715576172], [190.6529312133789, 438.7717590332031], [190.530517578125, 128.10652923583984], [560.850341796875, 534.1586761474609], [481.49298095703125, 322.7660675048828], [556.9756164550781, 404.9252624511719], [261.921142578125, 367.7220916748047], [552.4339904785156, 740.4807739257812], [99.54841995239258, 426.09324645996094], [615.9194641113281, 911.9180297851562], [52.44707489013672, 690.1251220703125], [555.1921081542969, 643.8731079101562], [772.5315246582031, 898.30908203125], [445.1993713378906, 353.86314392089844], [863.9230346679688, 717.4561157226562], [9.528563499450684, 687.9607238769531], [116.78031158447266, 439.0411071777344], [86.65597534179688, 420.28033447265625], [561.42431640625, 423.86895751953125], [52.160308837890625, 697.4062194824219], [10.457242965698242, 205.6795425415039], [784.8397827148438, 172.94344329833984], [98.34079360961914, 428.47914123535156], [59.88740348815918, 708.5267639160156], [868.4024658203125, 612.0582275390625], [46.88976860046387, 684.0860443115234], [6.2669501304626465, 402.6374206542969]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detectionResults[0]"
      ],
      "metadata": {
        "id": "wgTuIKGD7XpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and re-load prediction results"
      ],
      "metadata": {
        "id": "q2D1J1mlKOUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save as pkl\n",
        "with open('prediction_results.pkl', 'wb') as f:\n",
        "    pickle.dump(detectionResults, f)\n",
        "\n",
        "# Download the file\n",
        "files.download('prediction_results.pkl')"
      ],
      "metadata": {
        "id": "3txCCLNLJCiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved dictionary\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Make sure the key matches the file name you have uploaded\n",
        "with open('my_data.pkl', 'rb') as f:\n",
        "    my_list = pickle.load(f)"
      ],
      "metadata": {
        "id": "B4k6nTycJEY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BONUS: using a model via gradio on your phone"
      ],
      "metadata": {
        "id": "8ZiCgJGUOBJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gradio dependencies\n",
        "!pip install gradio\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import torch"
      ],
      "metadata": {
        "id": "-FP9LwpJOFAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image):\n",
        "    # Convert PIL Image to file path if needed by YOLO\n",
        "    image.save('/content/temp_image.jpg')\n",
        "    results = model_gr.predict(source='/content/temp_image.jpg', conf=0.25)\n",
        "\n",
        "    results[0].plot(conf=False, line_width=2, labels=True, pil=True)\n",
        "\n",
        "    # get counts and detection\n",
        "    detectionCount, detectionLocation = getDetectionCountsAndLocation(results[0])\n",
        "\n",
        "    # Convert tensor to image\n",
        "    output_image =  results[0].plot(conf=False, line_width=2, labels=True, pil=True)\n",
        "\n",
        "    return output_image, \"objects detected:\" + str(detectionCount)\n",
        "\n"
      ],
      "metadata": {
        "id": "3FYd_cA7OtKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a model\n",
        "path_to_model_gr = f'/content/runs/detect/train3/weights/best.pt'\n",
        "model_gr = YOLO(path_to_model_gr)"
      ],
      "metadata": {
        "id": "EEzGOt5rPpKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[gr.Image(type=\"pil\"), gr.Textbox()],\n",
        "    title=\"YOLOv8 Object Detection\",\n",
        "    description=\"Upload an image to detect objects using YOLOv8\"\n",
        ")\n",
        "# Launch the app\n",
        "iface.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "RAIfTfN2OuXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}